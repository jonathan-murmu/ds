{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression Exercise \n",
    "\n",
    "California Housing Data\n",
    "\n",
    "This data set contains information about all the block groups in California from the 1990 Census. In this sample a block group on average includes 1425.5 individuals living in a geographically compact area. \n",
    "\n",
    "The task is to aproximate the median house value of each block from the values of the rest of the variables. \n",
    "\n",
    " It has been obtained from the LIACC repository. The original page where the data set can be found is: http://www.liaad.up.pt/~ltorgo/Regression/DataSets.html.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The Features:\n",
    " \n",
    "* housingMedianAge: continuous. \n",
    "* totalRooms: continuous. \n",
    "* totalBedrooms: continuous. \n",
    "* population: continuous. \n",
    "* households: continuous. \n",
    "* medianIncome: continuous. \n",
    "* medianHouseValue: continuous. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Import the cal_housing_clean.csv file with pandas. Separate it into a training (70%) and testing set(30%).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "house_df = pd.read_csv('./cal_housing_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>housingMedianAge</th>\n",
       "      <th>totalRooms</th>\n",
       "      <th>totalBedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>medianIncome</th>\n",
       "      <th>medianHouseValue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41.0</td>\n",
       "      <td>880.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>322.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>8.3252</td>\n",
       "      <td>452600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21.0</td>\n",
       "      <td>7099.0</td>\n",
       "      <td>1106.0</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>1138.0</td>\n",
       "      <td>8.3014</td>\n",
       "      <td>358500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>52.0</td>\n",
       "      <td>1467.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>496.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>7.2574</td>\n",
       "      <td>352100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>52.0</td>\n",
       "      <td>1274.0</td>\n",
       "      <td>235.0</td>\n",
       "      <td>558.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>5.6431</td>\n",
       "      <td>341300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>52.0</td>\n",
       "      <td>1627.0</td>\n",
       "      <td>280.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>259.0</td>\n",
       "      <td>3.8462</td>\n",
       "      <td>342200.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   housingMedianAge  totalRooms  totalBedrooms  population  households  \\\n",
       "0              41.0       880.0          129.0       322.0       126.0   \n",
       "1              21.0      7099.0         1106.0      2401.0      1138.0   \n",
       "2              52.0      1467.0          190.0       496.0       177.0   \n",
       "3              52.0      1274.0          235.0       558.0       219.0   \n",
       "4              52.0      1627.0          280.0       565.0       259.0   \n",
       "\n",
       "   medianIncome  medianHouseValue  \n",
       "0        8.3252          452600.0  \n",
       "1        8.3014          358500.0  \n",
       "2        7.2574          352100.0  \n",
       "3        5.6431          341300.0  \n",
       "4        3.8462          342200.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "house_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['housingMedianAge', 'totalRooms', 'totalBedrooms', 'population',\n",
       "       'households', 'medianIncome', 'medianHouseValue'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "house_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>housingMedianAge</th>\n",
       "      <td>20640.0</td>\n",
       "      <td>28.639486</td>\n",
       "      <td>12.585558</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>18.0000</td>\n",
       "      <td>29.0000</td>\n",
       "      <td>37.00000</td>\n",
       "      <td>52.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>totalRooms</th>\n",
       "      <td>20640.0</td>\n",
       "      <td>2635.763081</td>\n",
       "      <td>2181.615252</td>\n",
       "      <td>2.0000</td>\n",
       "      <td>1447.7500</td>\n",
       "      <td>2127.0000</td>\n",
       "      <td>3148.00000</td>\n",
       "      <td>39320.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>totalBedrooms</th>\n",
       "      <td>20640.0</td>\n",
       "      <td>537.898014</td>\n",
       "      <td>421.247906</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>295.0000</td>\n",
       "      <td>435.0000</td>\n",
       "      <td>647.00000</td>\n",
       "      <td>6445.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>population</th>\n",
       "      <td>20640.0</td>\n",
       "      <td>1425.476744</td>\n",
       "      <td>1132.462122</td>\n",
       "      <td>3.0000</td>\n",
       "      <td>787.0000</td>\n",
       "      <td>1166.0000</td>\n",
       "      <td>1725.00000</td>\n",
       "      <td>35682.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>households</th>\n",
       "      <td>20640.0</td>\n",
       "      <td>499.539680</td>\n",
       "      <td>382.329753</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>280.0000</td>\n",
       "      <td>409.0000</td>\n",
       "      <td>605.00000</td>\n",
       "      <td>6082.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>medianIncome</th>\n",
       "      <td>20640.0</td>\n",
       "      <td>3.870671</td>\n",
       "      <td>1.899822</td>\n",
       "      <td>0.4999</td>\n",
       "      <td>2.5634</td>\n",
       "      <td>3.5348</td>\n",
       "      <td>4.74325</td>\n",
       "      <td>15.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>medianHouseValue</th>\n",
       "      <td>20640.0</td>\n",
       "      <td>206855.816909</td>\n",
       "      <td>115395.615874</td>\n",
       "      <td>14999.0000</td>\n",
       "      <td>119600.0000</td>\n",
       "      <td>179700.0000</td>\n",
       "      <td>264725.00000</td>\n",
       "      <td>500001.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    count           mean            std         min  \\\n",
       "housingMedianAge  20640.0      28.639486      12.585558      1.0000   \n",
       "totalRooms        20640.0    2635.763081    2181.615252      2.0000   \n",
       "totalBedrooms     20640.0     537.898014     421.247906      1.0000   \n",
       "population        20640.0    1425.476744    1132.462122      3.0000   \n",
       "households        20640.0     499.539680     382.329753      1.0000   \n",
       "medianIncome      20640.0       3.870671       1.899822      0.4999   \n",
       "medianHouseValue  20640.0  206855.816909  115395.615874  14999.0000   \n",
       "\n",
       "                          25%          50%           75%          max  \n",
       "housingMedianAge      18.0000      29.0000      37.00000      52.0000  \n",
       "totalRooms          1447.7500    2127.0000    3148.00000   39320.0000  \n",
       "totalBedrooms        295.0000     435.0000     647.00000    6445.0000  \n",
       "population           787.0000    1166.0000    1725.00000   35682.0000  \n",
       "households           280.0000     409.0000     605.00000    6082.0000  \n",
       "medianIncome           2.5634       3.5348       4.74325      15.0001  \n",
       "medianHouseValue  119600.0000  179700.0000  264725.00000  500001.0000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "house_df.describe().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_data = house_df.drop('medianHouseValue', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    452600.0\n",
       "1    358500.0\n",
       "2    352100.0\n",
       "3    341300.0\n",
       "4    342200.0\n",
       "Name: medianHouseValue, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_data = house_df['medianHouseValue']\n",
    "y_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.33, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13828, 6)\n",
      "(6812, 6)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale the Feature Data\n",
    "\n",
    "** Use sklearn preprocessing to create a MinMaxScaler for the feature data. Fit this scaler only to the training data. Then use it to transform X_test and X_train. Then use the scaled X_test and X_train along with pd.Dataframe to re-create two dataframes of scaled data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MinMaxScaler(copy=True, feature_range=(0, 1))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.DataFrame(data=scaler.transform(X_train), columns=X_train.columns, index=X_train.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = pd.DataFrame(data=scaler.transform(X_test), columns=X_test.columns, index=X_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>housingMedianAge</th>\n",
       "      <th>totalRooms</th>\n",
       "      <th>totalBedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>medianIncome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16624</th>\n",
       "      <td>0.509804</td>\n",
       "      <td>0.072766</td>\n",
       "      <td>0.110180</td>\n",
       "      <td>0.032455</td>\n",
       "      <td>0.087486</td>\n",
       "      <td>0.146246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14848</th>\n",
       "      <td>0.352941</td>\n",
       "      <td>0.092400</td>\n",
       "      <td>0.167132</td>\n",
       "      <td>0.109372</td>\n",
       "      <td>0.180398</td>\n",
       "      <td>0.056834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11081</th>\n",
       "      <td>0.647059</td>\n",
       "      <td>0.050918</td>\n",
       "      <td>0.051210</td>\n",
       "      <td>0.029409</td>\n",
       "      <td>0.053774</td>\n",
       "      <td>0.213107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>930</th>\n",
       "      <td>0.431373</td>\n",
       "      <td>0.080574</td>\n",
       "      <td>0.082402</td>\n",
       "      <td>0.050520</td>\n",
       "      <td>0.084526</td>\n",
       "      <td>0.271431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5889</th>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.077980</td>\n",
       "      <td>0.117163</td>\n",
       "      <td>0.041557</td>\n",
       "      <td>0.114126</td>\n",
       "      <td>0.211294</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       housingMedianAge  totalRooms  totalBedrooms  population  households  \\\n",
       "16624          0.509804    0.072766       0.110180    0.032455    0.087486   \n",
       "14848          0.352941    0.092400       0.167132    0.109372    0.180398   \n",
       "11081          0.647059    0.050918       0.051210    0.029409    0.053774   \n",
       "930            0.431373    0.080574       0.082402    0.050520    0.084526   \n",
       "5889           0.764706    0.077980       0.117163    0.041557    0.114126   \n",
       "\n",
       "       medianIncome  \n",
       "16624      0.146246  \n",
       "14848      0.056834  \n",
       "11081      0.213107  \n",
       "930        0.271431  \n",
       "5889       0.211294  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Feature Columns\n",
    "\n",
    "** Create the necessary tf.feature_column objects for the estimator. They should all be trated as continuous numeric_columns. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['housingMedianAge', 'totalRooms', 'totalBedrooms', 'population',\n",
       "       'households', 'medianIncome'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "age = tf.feature_column.numeric_column('housingMedianAge')\n",
    "rooms = tf.feature_column.numeric_column('totalRooms')\n",
    "bedrooms = tf.feature_column.numeric_column('totalBedrooms')\n",
    "population = tf.feature_column.numeric_column('population')\n",
    "households = tf.feature_column.numeric_column('households')\n",
    "income = tf.feature_column.numeric_column('medianIncome')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = [age, rooms, bedrooms, population, households, income]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Create the input function for the estimator object. (play around with batch_size and num_epochs)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_func = tf.estimator.inputs.pandas_input_fn(x=X_train,y=y_train ,batch_size=10,num_epochs=1000,\n",
    "                                            shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Create the estimator model. Use a DNNRegressor. Play around with the hidden units! **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /var/folders/0t/3d36yk2909g3l_5vhfrmv5gr0000gn/T/tmpxik1dusy\n",
      "INFO:tensorflow:Using config: {'_global_id_in_cluster': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fa3b7df6160>, '_log_step_count_steps': 100, '_eval_distribute': None, '_save_checkpoints_steps': None, '_task_id': 0, '_experimental_max_worker_delay_secs': None, '_is_chief': True, '_service': None, '_num_ps_replicas': 0, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_save_summary_steps': 100, '_train_distribute': None, '_protocol': None, '_device_fn': None, '_experimental_distribute': None, '_model_dir': '/var/folders/0t/3d36yk2909g3l_5vhfrmv5gr0000gn/T/tmpxik1dusy', '_task_type': 'worker', '_keep_checkpoint_max': 5, '_save_checkpoints_secs': 600, '_master': '', '_session_creation_timeout_secs': 7200, '_num_worker_replicas': 1, '_keep_checkpoint_every_n_hours': 10000, '_evaluation_master': '', '_tf_random_seed': None}\n"
     ]
    }
   ],
   "source": [
    "model = tf.estimator.DNNRegressor(hidden_units=[6,6,6],feature_columns=feature_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ** Train the model for ~1,000 steps. (Later come back to this and train it for more and check for improvement) **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/0t/3d36yk2909g3l_5vhfrmv5gr0000gn/T/tmpxik1dusy/model.ckpt-26000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 26000 into /var/folders/0t/3d36yk2909g3l_5vhfrmv5gr0000gn/T/tmpxik1dusy/model.ckpt.\n",
      "INFO:tensorflow:loss = 96026240000.0, step = 26001\n",
      "INFO:tensorflow:global_step/sec: 251.778\n",
      "INFO:tensorflow:loss = 81157560000.0, step = 26101 (0.399 sec)\n",
      "INFO:tensorflow:global_step/sec: 293.382\n",
      "INFO:tensorflow:loss = 116195844000.0, step = 26201 (0.340 sec)\n",
      "INFO:tensorflow:global_step/sec: 282.723\n",
      "INFO:tensorflow:loss = 136027865000.0, step = 26301 (0.354 sec)\n",
      "INFO:tensorflow:global_step/sec: 313.628\n",
      "INFO:tensorflow:loss = 162329560000.0, step = 26401 (0.319 sec)\n",
      "INFO:tensorflow:global_step/sec: 314.771\n",
      "INFO:tensorflow:loss = 104749970000.0, step = 26501 (0.324 sec)\n",
      "INFO:tensorflow:global_step/sec: 311.513\n",
      "INFO:tensorflow:loss = 62666596000.0, step = 26601 (0.315 sec)\n",
      "INFO:tensorflow:global_step/sec: 297.095\n",
      "INFO:tensorflow:loss = 180165020000.0, step = 26701 (0.341 sec)\n",
      "INFO:tensorflow:global_step/sec: 287.524\n",
      "INFO:tensorflow:loss = 93670550000.0, step = 26801 (0.344 sec)\n",
      "INFO:tensorflow:global_step/sec: 316.955\n",
      "INFO:tensorflow:loss = 86601564000.0, step = 26901 (0.320 sec)\n",
      "INFO:tensorflow:global_step/sec: 287.905\n",
      "INFO:tensorflow:loss = 105164420000.0, step = 27001 (0.343 sec)\n",
      "INFO:tensorflow:global_step/sec: 291.258\n",
      "INFO:tensorflow:loss = 51304948000.0, step = 27101 (0.344 sec)\n",
      "INFO:tensorflow:global_step/sec: 290.574\n",
      "INFO:tensorflow:loss = 55003046000.0, step = 27201 (0.344 sec)\n",
      "INFO:tensorflow:global_step/sec: 292.25\n",
      "INFO:tensorflow:loss = 240065250000.0, step = 27301 (0.342 sec)\n",
      "INFO:tensorflow:global_step/sec: 313.436\n",
      "INFO:tensorflow:loss = 112156710000.0, step = 27401 (0.321 sec)\n",
      "INFO:tensorflow:global_step/sec: 300.963\n",
      "INFO:tensorflow:loss = 34420093000.0, step = 27501 (0.330 sec)\n",
      "INFO:tensorflow:global_step/sec: 302.153\n",
      "INFO:tensorflow:loss = 71773550000.0, step = 27601 (0.331 sec)\n",
      "INFO:tensorflow:global_step/sec: 315.898\n",
      "INFO:tensorflow:loss = 101415354000.0, step = 27701 (0.319 sec)\n",
      "INFO:tensorflow:global_step/sec: 309.672\n",
      "INFO:tensorflow:loss = 90492330000.0, step = 27801 (0.323 sec)\n",
      "INFO:tensorflow:global_step/sec: 285.807\n",
      "INFO:tensorflow:loss = 58416407000.0, step = 27901 (0.347 sec)\n",
      "INFO:tensorflow:global_step/sec: 297.499\n",
      "INFO:tensorflow:loss = 47349060000.0, step = 28001 (0.336 sec)\n",
      "INFO:tensorflow:global_step/sec: 290.067\n",
      "INFO:tensorflow:loss = 66071777000.0, step = 28101 (0.345 sec)\n",
      "INFO:tensorflow:global_step/sec: 309.057\n",
      "INFO:tensorflow:loss = 78443315000.0, step = 28201 (0.324 sec)\n",
      "INFO:tensorflow:global_step/sec: 313.323\n",
      "INFO:tensorflow:loss = 86792260000.0, step = 28301 (0.321 sec)\n",
      "INFO:tensorflow:global_step/sec: 281.998\n",
      "INFO:tensorflow:loss = 54602500000.0, step = 28401 (0.358 sec)\n",
      "INFO:tensorflow:global_step/sec: 281.615\n",
      "INFO:tensorflow:loss = 67020857000.0, step = 28501 (0.350 sec)\n",
      "INFO:tensorflow:global_step/sec: 288.511\n",
      "INFO:tensorflow:loss = 61825000000.0, step = 28601 (0.347 sec)\n",
      "INFO:tensorflow:global_step/sec: 281.383\n",
      "INFO:tensorflow:loss = 110572650000.0, step = 28701 (0.355 sec)\n",
      "INFO:tensorflow:global_step/sec: 283.054\n",
      "INFO:tensorflow:loss = 84353060000.0, step = 28801 (0.353 sec)\n",
      "INFO:tensorflow:global_step/sec: 237.973\n",
      "INFO:tensorflow:loss = 62095800000.0, step = 28901 (0.420 sec)\n",
      "INFO:tensorflow:global_step/sec: 287.077\n",
      "INFO:tensorflow:loss = 131241470000.0, step = 29001 (0.364 sec)\n",
      "INFO:tensorflow:global_step/sec: 307.855\n",
      "INFO:tensorflow:loss = 109677560000.0, step = 29101 (0.317 sec)\n",
      "INFO:tensorflow:global_step/sec: 293.382\n",
      "INFO:tensorflow:loss = 171410240000.0, step = 29201 (0.338 sec)\n",
      "INFO:tensorflow:global_step/sec: 301.226\n",
      "INFO:tensorflow:loss = 70409420000.0, step = 29301 (0.334 sec)\n",
      "INFO:tensorflow:global_step/sec: 280.484\n",
      "INFO:tensorflow:loss = 157700700000.0, step = 29401 (0.350 sec)\n",
      "INFO:tensorflow:global_step/sec: 279.721\n",
      "INFO:tensorflow:loss = 71309910000.0, step = 29501 (0.356 sec)\n",
      "INFO:tensorflow:global_step/sec: 313.929\n",
      "INFO:tensorflow:loss = 56878660000.0, step = 29601 (0.319 sec)\n",
      "INFO:tensorflow:global_step/sec: 313.906\n",
      "INFO:tensorflow:loss = 147655900000.0, step = 29701 (0.326 sec)\n",
      "INFO:tensorflow:global_step/sec: 281.825\n",
      "INFO:tensorflow:loss = 80676640000.0, step = 29801 (0.348 sec)\n",
      "INFO:tensorflow:global_step/sec: 283.751\n",
      "INFO:tensorflow:loss = 140156700000.0, step = 29901 (0.352 sec)\n",
      "INFO:tensorflow:global_step/sec: 311.22\n",
      "INFO:tensorflow:loss = 58240627000.0, step = 30001 (0.326 sec)\n",
      "INFO:tensorflow:global_step/sec: 285.533\n",
      "INFO:tensorflow:loss = 34520584000.0, step = 30101 (0.346 sec)\n",
      "INFO:tensorflow:global_step/sec: 287.249\n",
      "INFO:tensorflow:loss = 117209460000.0, step = 30201 (0.348 sec)\n",
      "INFO:tensorflow:global_step/sec: 294.495\n",
      "INFO:tensorflow:loss = 50432480000.0, step = 30301 (0.339 sec)\n",
      "INFO:tensorflow:global_step/sec: 293.143\n",
      "INFO:tensorflow:loss = 80193910000.0, step = 30401 (0.341 sec)\n",
      "INFO:tensorflow:global_step/sec: 292.087\n",
      "INFO:tensorflow:loss = 57794910000.0, step = 30501 (0.342 sec)\n",
      "INFO:tensorflow:global_step/sec: 294.039\n",
      "INFO:tensorflow:loss = 92185060000.0, step = 30601 (0.341 sec)\n",
      "INFO:tensorflow:global_step/sec: 292.456\n",
      "INFO:tensorflow:loss = 58595353000.0, step = 30701 (0.342 sec)\n",
      "INFO:tensorflow:global_step/sec: 291.325\n",
      "INFO:tensorflow:loss = 37852170000.0, step = 30801 (0.343 sec)\n",
      "INFO:tensorflow:global_step/sec: 289.594\n",
      "INFO:tensorflow:loss = 44340466000.0, step = 30901 (0.345 sec)\n",
      "INFO:tensorflow:global_step/sec: 297.523\n",
      "INFO:tensorflow:loss = 45237990000.0, step = 31001 (0.337 sec)\n",
      "INFO:tensorflow:global_step/sec: 302.731\n",
      "INFO:tensorflow:loss = 104805010000.0, step = 31101 (0.330 sec)\n",
      "INFO:tensorflow:global_step/sec: 298.305\n",
      "INFO:tensorflow:loss = 96099000000.0, step = 31201 (0.335 sec)\n",
      "INFO:tensorflow:global_step/sec: 297.956\n",
      "INFO:tensorflow:loss = 83396390000.0, step = 31301 (0.336 sec)\n",
      "INFO:tensorflow:global_step/sec: 310.309\n",
      "INFO:tensorflow:loss = 165801790000.0, step = 31401 (0.322 sec)\n",
      "INFO:tensorflow:global_step/sec: 258.414\n",
      "INFO:tensorflow:loss = 72840430000.0, step = 31501 (0.401 sec)\n",
      "INFO:tensorflow:global_step/sec: 278.104\n",
      "INFO:tensorflow:loss = 82941930000.0, step = 31601 (0.346 sec)\n",
      "INFO:tensorflow:global_step/sec: 300.134\n",
      "INFO:tensorflow:loss = 41206882000.0, step = 31701 (0.333 sec)\n",
      "INFO:tensorflow:global_step/sec: 316.711\n",
      "INFO:tensorflow:loss = 90944090000.0, step = 31801 (0.318 sec)\n",
      "INFO:tensorflow:global_step/sec: 294.108\n",
      "INFO:tensorflow:loss = 167660930000.0, step = 31901 (0.338 sec)\n",
      "INFO:tensorflow:global_step/sec: 295.407\n",
      "INFO:tensorflow:loss = 48098976000.0, step = 32001 (0.339 sec)\n",
      "INFO:tensorflow:global_step/sec: 311.223\n",
      "INFO:tensorflow:loss = 157129790000.0, step = 32101 (0.321 sec)\n",
      "INFO:tensorflow:global_step/sec: 305.216\n",
      "INFO:tensorflow:loss = 56896770000.0, step = 32201 (0.328 sec)\n",
      "INFO:tensorflow:global_step/sec: 308.489\n",
      "INFO:tensorflow:loss = 87257180000.0, step = 32301 (0.324 sec)\n",
      "INFO:tensorflow:global_step/sec: 329.953\n",
      "INFO:tensorflow:loss = 44237280000.0, step = 32401 (0.313 sec)\n",
      "INFO:tensorflow:global_step/sec: 295.897\n",
      "INFO:tensorflow:loss = 151242870000.0, step = 32501 (0.328 sec)\n",
      "INFO:tensorflow:global_step/sec: 302.52\n",
      "INFO:tensorflow:loss = 89289360000.0, step = 32601 (0.331 sec)\n",
      "INFO:tensorflow:global_step/sec: 299.881\n",
      "INFO:tensorflow:loss = 63956976000.0, step = 32701 (0.333 sec)\n",
      "INFO:tensorflow:global_step/sec: 289.089\n",
      "INFO:tensorflow:loss = 69459940000.0, step = 32801 (0.346 sec)\n",
      "INFO:tensorflow:global_step/sec: 311.413\n",
      "INFO:tensorflow:loss = 52855677000.0, step = 32901 (0.324 sec)\n",
      "INFO:tensorflow:global_step/sec: 297.244\n",
      "INFO:tensorflow:loss = 89324620000.0, step = 33001 (0.334 sec)\n",
      "INFO:tensorflow:global_step/sec: 297.859\n",
      "INFO:tensorflow:loss = 57168257000.0, step = 33101 (0.336 sec)\n",
      "INFO:tensorflow:global_step/sec: 299.11\n",
      "INFO:tensorflow:loss = 126044680000.0, step = 33201 (0.334 sec)\n",
      "INFO:tensorflow:global_step/sec: 307.153\n",
      "INFO:tensorflow:loss = 80121380000.0, step = 33301 (0.328 sec)\n",
      "INFO:tensorflow:global_step/sec: 287.465\n",
      "INFO:tensorflow:loss = 139800180000.0, step = 33401 (0.345 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 299.838\n",
      "INFO:tensorflow:loss = 58077397000.0, step = 33501 (0.333 sec)\n",
      "INFO:tensorflow:global_step/sec: 313.067\n",
      "INFO:tensorflow:loss = 43685315000.0, step = 33601 (0.319 sec)\n",
      "INFO:tensorflow:global_step/sec: 301.46\n",
      "INFO:tensorflow:loss = 225716700000.0, step = 33701 (0.332 sec)\n",
      "INFO:tensorflow:global_step/sec: 312.558\n",
      "INFO:tensorflow:loss = 48014713000.0, step = 33801 (0.320 sec)\n",
      "INFO:tensorflow:global_step/sec: 325.128\n",
      "INFO:tensorflow:loss = 60974158000.0, step = 33901 (0.310 sec)\n",
      "INFO:tensorflow:global_step/sec: 294.319\n",
      "INFO:tensorflow:loss = 110434200000.0, step = 34001 (0.338 sec)\n",
      "INFO:tensorflow:global_step/sec: 298.443\n",
      "INFO:tensorflow:loss = 99492364000.0, step = 34101 (0.335 sec)\n",
      "INFO:tensorflow:global_step/sec: 299.113\n",
      "INFO:tensorflow:loss = 61603963000.0, step = 34201 (0.335 sec)\n",
      "INFO:tensorflow:global_step/sec: 296.385\n",
      "INFO:tensorflow:loss = 56482296000.0, step = 34301 (0.337 sec)\n",
      "INFO:tensorflow:global_step/sec: 322.194\n",
      "INFO:tensorflow:loss = 121889240000.0, step = 34401 (0.310 sec)\n",
      "INFO:tensorflow:global_step/sec: 302.61\n",
      "INFO:tensorflow:loss = 44776206000.0, step = 34501 (0.330 sec)\n",
      "INFO:tensorflow:global_step/sec: 295.332\n",
      "INFO:tensorflow:loss = 65602216000.0, step = 34601 (0.339 sec)\n",
      "INFO:tensorflow:global_step/sec: 323.134\n",
      "INFO:tensorflow:loss = 15716127000.0, step = 34701 (0.309 sec)\n",
      "INFO:tensorflow:global_step/sec: 301.649\n",
      "INFO:tensorflow:loss = 75642225000.0, step = 34801 (0.331 sec)\n",
      "INFO:tensorflow:global_step/sec: 276.312\n",
      "INFO:tensorflow:loss = 54801072000.0, step = 34901 (0.362 sec)\n",
      "INFO:tensorflow:global_step/sec: 257.033\n",
      "INFO:tensorflow:loss = 106780430000.0, step = 35001 (0.389 sec)\n",
      "INFO:tensorflow:global_step/sec: 269.748\n",
      "INFO:tensorflow:loss = 85669380000.0, step = 35101 (0.371 sec)\n",
      "INFO:tensorflow:global_step/sec: 295.98\n",
      "INFO:tensorflow:loss = 245421410000.0, step = 35201 (0.338 sec)\n",
      "INFO:tensorflow:global_step/sec: 325.765\n",
      "INFO:tensorflow:loss = 61594866000.0, step = 35301 (0.309 sec)\n",
      "INFO:tensorflow:global_step/sec: 324.877\n",
      "INFO:tensorflow:loss = 55116497000.0, step = 35401 (0.311 sec)\n",
      "INFO:tensorflow:global_step/sec: 295.339\n",
      "INFO:tensorflow:loss = 42389467000.0, step = 35501 (0.333 sec)\n",
      "INFO:tensorflow:global_step/sec: 319.933\n",
      "INFO:tensorflow:loss = 93587790000.0, step = 35601 (0.312 sec)\n",
      "INFO:tensorflow:global_step/sec: 313.575\n",
      "INFO:tensorflow:loss = 39980580000.0, step = 35701 (0.319 sec)\n",
      "INFO:tensorflow:global_step/sec: 289.685\n",
      "INFO:tensorflow:loss = 49019433000.0, step = 35801 (0.345 sec)\n",
      "INFO:tensorflow:global_step/sec: 299.416\n",
      "INFO:tensorflow:loss = 51780977000.0, step = 35901 (0.334 sec)\n",
      "INFO:tensorflow:global_step/sec: 325.121\n",
      "INFO:tensorflow:loss = 48776503000.0, step = 36001 (0.312 sec)\n",
      "INFO:tensorflow:global_step/sec: 317.718\n",
      "INFO:tensorflow:loss = 133501940000.0, step = 36101 (0.310 sec)\n",
      "INFO:tensorflow:global_step/sec: 307.814\n",
      "INFO:tensorflow:loss = 91365210000.0, step = 36201 (0.325 sec)\n",
      "INFO:tensorflow:global_step/sec: 317.953\n",
      "INFO:tensorflow:loss = 114434910000.0, step = 36301 (0.315 sec)\n",
      "INFO:tensorflow:global_step/sec: 322.434\n",
      "INFO:tensorflow:loss = 62757760000.0, step = 36401 (0.312 sec)\n",
      "INFO:tensorflow:global_step/sec: 310.128\n",
      "INFO:tensorflow:loss = 88056120000.0, step = 36501 (0.327 sec)\n",
      "INFO:tensorflow:global_step/sec: 308.507\n",
      "INFO:tensorflow:loss = 112968630000.0, step = 36601 (0.318 sec)\n",
      "INFO:tensorflow:global_step/sec: 296.336\n",
      "INFO:tensorflow:loss = 121565420000.0, step = 36701 (0.337 sec)\n",
      "INFO:tensorflow:global_step/sec: 303.853\n",
      "INFO:tensorflow:loss = 63830250000.0, step = 36801 (0.329 sec)\n",
      "INFO:tensorflow:global_step/sec: 321.313\n",
      "INFO:tensorflow:loss = 82668536000.0, step = 36901 (0.311 sec)\n",
      "INFO:tensorflow:global_step/sec: 318.519\n",
      "INFO:tensorflow:loss = 70529320000.0, step = 37001 (0.321 sec)\n",
      "INFO:tensorflow:global_step/sec: 279.005\n",
      "INFO:tensorflow:loss = 89224240000.0, step = 37101 (0.351 sec)\n",
      "INFO:tensorflow:global_step/sec: 279.822\n",
      "INFO:tensorflow:loss = 65343767000.0, step = 37201 (0.357 sec)\n",
      "INFO:tensorflow:global_step/sec: 315.714\n",
      "INFO:tensorflow:loss = 44871406000.0, step = 37301 (0.317 sec)\n",
      "INFO:tensorflow:global_step/sec: 312.24\n",
      "INFO:tensorflow:loss = 107780420000.0, step = 37401 (0.320 sec)\n",
      "INFO:tensorflow:global_step/sec: 303.619\n",
      "INFO:tensorflow:loss = 32408949000.0, step = 37501 (0.330 sec)\n",
      "INFO:tensorflow:global_step/sec: 303.825\n",
      "INFO:tensorflow:loss = 76347790000.0, step = 37601 (0.331 sec)\n",
      "INFO:tensorflow:global_step/sec: 299.478\n",
      "INFO:tensorflow:loss = 182066820000.0, step = 37701 (0.332 sec)\n",
      "INFO:tensorflow:global_step/sec: 300.431\n",
      "INFO:tensorflow:loss = 135743365000.0, step = 37801 (0.333 sec)\n",
      "INFO:tensorflow:global_step/sec: 300.442\n",
      "INFO:tensorflow:loss = 121449960000.0, step = 37901 (0.335 sec)\n",
      "INFO:tensorflow:global_step/sec: 267.459\n",
      "INFO:tensorflow:loss = 60358310000.0, step = 38001 (0.372 sec)\n",
      "INFO:tensorflow:global_step/sec: 268.292\n",
      "INFO:tensorflow:loss = 54351870000.0, step = 38101 (0.373 sec)\n",
      "INFO:tensorflow:global_step/sec: 267.679\n",
      "INFO:tensorflow:loss = 106658830000.0, step = 38201 (0.373 sec)\n",
      "INFO:tensorflow:global_step/sec: 300.412\n",
      "INFO:tensorflow:loss = 137481900000.0, step = 38301 (0.333 sec)\n",
      "INFO:tensorflow:global_step/sec: 300.084\n",
      "INFO:tensorflow:loss = 165680500000.0, step = 38401 (0.334 sec)\n",
      "INFO:tensorflow:global_step/sec: 312.994\n",
      "INFO:tensorflow:loss = 62526603000.0, step = 38501 (0.319 sec)\n",
      "INFO:tensorflow:global_step/sec: 282.649\n",
      "INFO:tensorflow:loss = 64412370000.0, step = 38601 (0.354 sec)\n",
      "INFO:tensorflow:global_step/sec: 320.502\n",
      "INFO:tensorflow:loss = 39770878000.0, step = 38701 (0.312 sec)\n",
      "INFO:tensorflow:global_step/sec: 294.861\n",
      "INFO:tensorflow:loss = 116514140000.0, step = 38801 (0.339 sec)\n",
      "INFO:tensorflow:global_step/sec: 240.74\n",
      "INFO:tensorflow:loss = 49972957000.0, step = 38901 (0.416 sec)\n",
      "INFO:tensorflow:global_step/sec: 233.335\n",
      "INFO:tensorflow:loss = 81897010000.0, step = 39001 (0.451 sec)\n",
      "INFO:tensorflow:global_step/sec: 267.468\n",
      "INFO:tensorflow:loss = 127010930000.0, step = 39101 (0.357 sec)\n",
      "INFO:tensorflow:global_step/sec: 305.788\n",
      "INFO:tensorflow:loss = 82986690000.0, step = 39201 (0.323 sec)\n",
      "INFO:tensorflow:global_step/sec: 296.23\n",
      "INFO:tensorflow:loss = 65349984000.0, step = 39301 (0.339 sec)\n",
      "INFO:tensorflow:global_step/sec: 301.746\n",
      "INFO:tensorflow:loss = 85966360000.0, step = 39401 (0.330 sec)\n",
      "INFO:tensorflow:global_step/sec: 297.931\n",
      "INFO:tensorflow:loss = 132125200000.0, step = 39501 (0.334 sec)\n",
      "INFO:tensorflow:global_step/sec: 286.836\n",
      "INFO:tensorflow:loss = 69629360000.0, step = 39601 (0.348 sec)\n",
      "INFO:tensorflow:global_step/sec: 323.323\n",
      "INFO:tensorflow:loss = 54474592000.0, step = 39701 (0.313 sec)\n",
      "INFO:tensorflow:global_step/sec: 308.005\n",
      "INFO:tensorflow:loss = 63666328000.0, step = 39801 (0.321 sec)\n",
      "INFO:tensorflow:global_step/sec: 320.779\n",
      "INFO:tensorflow:loss = 92119220000.0, step = 39901 (0.316 sec)\n",
      "INFO:tensorflow:global_step/sec: 316.771\n",
      "INFO:tensorflow:loss = 86908980000.0, step = 40001 (0.320 sec)\n",
      "INFO:tensorflow:global_step/sec: 302.585\n",
      "INFO:tensorflow:loss = 61054190000.0, step = 40101 (0.322 sec)\n",
      "INFO:tensorflow:global_step/sec: 288.744\n",
      "INFO:tensorflow:loss = 75221344000.0, step = 40201 (0.346 sec)\n",
      "INFO:tensorflow:global_step/sec: 305.076\n",
      "INFO:tensorflow:loss = 82311496000.0, step = 40301 (0.328 sec)\n",
      "INFO:tensorflow:global_step/sec: 294.349\n",
      "INFO:tensorflow:loss = 90524746000.0, step = 40401 (0.340 sec)\n",
      "INFO:tensorflow:global_step/sec: 292.795\n",
      "INFO:tensorflow:loss = 80550870000.0, step = 40501 (0.342 sec)\n",
      "INFO:tensorflow:global_step/sec: 317.967\n",
      "INFO:tensorflow:loss = 22247205000.0, step = 40601 (0.315 sec)\n",
      "INFO:tensorflow:global_step/sec: 301.49\n",
      "INFO:tensorflow:loss = 159216340000.0, step = 40701 (0.332 sec)\n",
      "INFO:tensorflow:global_step/sec: 294.42\n",
      "INFO:tensorflow:loss = 28691014000.0, step = 40801 (0.339 sec)\n",
      "INFO:tensorflow:global_step/sec: 310.057\n",
      "INFO:tensorflow:loss = 83994190000.0, step = 40901 (0.323 sec)\n",
      "INFO:tensorflow:global_step/sec: 317.485\n",
      "INFO:tensorflow:loss = 162317840000.0, step = 41001 (0.314 sec)\n",
      "INFO:tensorflow:global_step/sec: 295.842\n",
      "INFO:tensorflow:loss = 57564307000.0, step = 41101 (0.338 sec)\n",
      "INFO:tensorflow:global_step/sec: 302.537\n",
      "INFO:tensorflow:loss = 94094260000.0, step = 41201 (0.331 sec)\n",
      "INFO:tensorflow:global_step/sec: 296.644\n",
      "INFO:tensorflow:loss = 84080796000.0, step = 41301 (0.337 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 324.548\n",
      "INFO:tensorflow:loss = 148933280000.0, step = 41401 (0.314 sec)\n",
      "INFO:tensorflow:global_step/sec: 308.938\n",
      "INFO:tensorflow:loss = 88197900000.0, step = 41501 (0.318 sec)\n",
      "INFO:tensorflow:global_step/sec: 321.423\n",
      "INFO:tensorflow:loss = 88411580000.0, step = 41601 (0.316 sec)\n",
      "INFO:tensorflow:global_step/sec: 307.039\n",
      "INFO:tensorflow:loss = 150462900000.0, step = 41701 (0.321 sec)\n",
      "INFO:tensorflow:global_step/sec: 297.294\n",
      "INFO:tensorflow:loss = 61022030000.0, step = 41801 (0.339 sec)\n",
      "INFO:tensorflow:global_step/sec: 315.641\n",
      "INFO:tensorflow:loss = 40137330000.0, step = 41901 (0.315 sec)\n",
      "INFO:tensorflow:global_step/sec: 296.367\n",
      "INFO:tensorflow:loss = 93365480000.0, step = 42001 (0.337 sec)\n",
      "INFO:tensorflow:global_step/sec: 293.302\n",
      "INFO:tensorflow:loss = 63486296000.0, step = 42101 (0.343 sec)\n",
      "INFO:tensorflow:global_step/sec: 313.091\n",
      "INFO:tensorflow:loss = 48924934000.0, step = 42201 (0.317 sec)\n",
      "INFO:tensorflow:global_step/sec: 299.746\n",
      "INFO:tensorflow:loss = 59626717000.0, step = 42301 (0.334 sec)\n",
      "INFO:tensorflow:global_step/sec: 294.384\n",
      "INFO:tensorflow:loss = 77187320000.0, step = 42401 (0.340 sec)\n",
      "INFO:tensorflow:global_step/sec: 319.948\n",
      "INFO:tensorflow:loss = 96460370000.0, step = 42501 (0.315 sec)\n",
      "INFO:tensorflow:global_step/sec: 299.922\n",
      "INFO:tensorflow:loss = 54260974000.0, step = 42601 (0.331 sec)\n",
      "INFO:tensorflow:global_step/sec: 297.326\n",
      "INFO:tensorflow:loss = 28823880000.0, step = 42701 (0.337 sec)\n",
      "INFO:tensorflow:global_step/sec: 299.771\n",
      "INFO:tensorflow:loss = 75269570000.0, step = 42801 (0.333 sec)\n",
      "INFO:tensorflow:global_step/sec: 320.18\n",
      "INFO:tensorflow:loss = 152150980000.0, step = 42901 (0.312 sec)\n",
      "INFO:tensorflow:global_step/sec: 299.471\n",
      "INFO:tensorflow:loss = 77883590000.0, step = 43001 (0.334 sec)\n",
      "INFO:tensorflow:global_step/sec: 302.332\n",
      "INFO:tensorflow:loss = 50650935000.0, step = 43101 (0.331 sec)\n",
      "INFO:tensorflow:global_step/sec: 329.253\n",
      "INFO:tensorflow:loss = 128923970000.0, step = 43201 (0.306 sec)\n",
      "INFO:tensorflow:global_step/sec: 322.387\n",
      "INFO:tensorflow:loss = 55339053000.0, step = 43301 (0.313 sec)\n",
      "INFO:tensorflow:global_step/sec: 302.036\n",
      "INFO:tensorflow:loss = 100695880000.0, step = 43401 (0.327 sec)\n",
      "INFO:tensorflow:global_step/sec: 319.197\n",
      "INFO:tensorflow:loss = 57951293000.0, step = 43501 (0.313 sec)\n",
      "INFO:tensorflow:global_step/sec: 288.282\n",
      "INFO:tensorflow:loss = 120746530000.0, step = 43601 (0.351 sec)\n",
      "INFO:tensorflow:global_step/sec: 290.03\n",
      "INFO:tensorflow:loss = 81588970000.0, step = 43701 (0.340 sec)\n",
      "INFO:tensorflow:global_step/sec: 286.814\n",
      "INFO:tensorflow:loss = 98483410000.0, step = 43801 (0.349 sec)\n",
      "INFO:tensorflow:global_step/sec: 293.762\n",
      "INFO:tensorflow:loss = 152734990000.0, step = 43901 (0.341 sec)\n",
      "INFO:tensorflow:global_step/sec: 292.505\n",
      "INFO:tensorflow:loss = 107199500000.0, step = 44001 (0.342 sec)\n",
      "INFO:tensorflow:global_step/sec: 258.489\n",
      "INFO:tensorflow:loss = 49005183000.0, step = 44101 (0.387 sec)\n",
      "INFO:tensorflow:global_step/sec: 253.68\n",
      "INFO:tensorflow:loss = 87717090000.0, step = 44201 (0.402 sec)\n",
      "INFO:tensorflow:global_step/sec: 292.426\n",
      "INFO:tensorflow:loss = 110002520000.0, step = 44301 (0.335 sec)\n",
      "INFO:tensorflow:global_step/sec: 300.534\n",
      "INFO:tensorflow:loss = 71993210000.0, step = 44401 (0.333 sec)\n",
      "INFO:tensorflow:global_step/sec: 299.17\n",
      "INFO:tensorflow:loss = 111749005000.0, step = 44501 (0.334 sec)\n",
      "INFO:tensorflow:global_step/sec: 324.564\n",
      "INFO:tensorflow:loss = 155087730000.0, step = 44601 (0.311 sec)\n",
      "INFO:tensorflow:global_step/sec: 312.517\n",
      "INFO:tensorflow:loss = 48803398000.0, step = 44701 (0.317 sec)\n",
      "INFO:tensorflow:global_step/sec: 291.685\n",
      "INFO:tensorflow:loss = 34986030000.0, step = 44801 (0.343 sec)\n",
      "INFO:tensorflow:global_step/sec: 300.715\n",
      "INFO:tensorflow:loss = 98650700000.0, step = 44901 (0.332 sec)\n",
      "INFO:tensorflow:global_step/sec: 290.192\n",
      "INFO:tensorflow:loss = 34119504000.0, step = 45001 (0.345 sec)\n",
      "INFO:tensorflow:global_step/sec: 303.126\n",
      "INFO:tensorflow:loss = 119256490000.0, step = 45101 (0.330 sec)\n",
      "INFO:tensorflow:global_step/sec: 302.331\n",
      "INFO:tensorflow:loss = 59333415000.0, step = 45201 (0.331 sec)\n",
      "INFO:tensorflow:global_step/sec: 301.538\n",
      "INFO:tensorflow:loss = 91534100000.0, step = 45301 (0.332 sec)\n",
      "INFO:tensorflow:global_step/sec: 311.49\n",
      "INFO:tensorflow:loss = 78949890000.0, step = 45401 (0.321 sec)\n",
      "INFO:tensorflow:global_step/sec: 302.064\n",
      "INFO:tensorflow:loss = 25755593000.0, step = 45501 (0.331 sec)\n",
      "INFO:tensorflow:global_step/sec: 300.584\n",
      "INFO:tensorflow:loss = 127025350000.0, step = 45601 (0.333 sec)\n",
      "INFO:tensorflow:global_step/sec: 325.9\n",
      "INFO:tensorflow:loss = 42859030000.0, step = 45701 (0.309 sec)\n",
      "INFO:tensorflow:global_step/sec: 298.732\n",
      "INFO:tensorflow:loss = 105947400000.0, step = 45801 (0.332 sec)\n",
      "INFO:tensorflow:global_step/sec: 316.574\n",
      "INFO:tensorflow:loss = 102251840000.0, step = 45901 (0.320 sec)\n",
      "INFO:tensorflow:global_step/sec: 298.864\n",
      "INFO:tensorflow:loss = 91944570000.0, step = 46001 (0.330 sec)\n",
      "INFO:tensorflow:global_step/sec: 298.704\n",
      "INFO:tensorflow:loss = 39026954000.0, step = 46101 (0.335 sec)\n",
      "INFO:tensorflow:global_step/sec: 304.066\n",
      "INFO:tensorflow:loss = 52394193000.0, step = 46201 (0.329 sec)\n",
      "INFO:tensorflow:global_step/sec: 308.932\n",
      "INFO:tensorflow:loss = 99362670000.0, step = 46301 (0.324 sec)\n",
      "INFO:tensorflow:global_step/sec: 318.775\n",
      "INFO:tensorflow:loss = 45768266000.0, step = 46401 (0.314 sec)\n",
      "INFO:tensorflow:global_step/sec: 304.456\n",
      "INFO:tensorflow:loss = 111948140000.0, step = 46501 (0.329 sec)\n",
      "INFO:tensorflow:global_step/sec: 296.615\n",
      "INFO:tensorflow:loss = 130832610000.0, step = 46601 (0.337 sec)\n",
      "INFO:tensorflow:global_step/sec: 319.401\n",
      "INFO:tensorflow:loss = 60126850000.0, step = 46701 (0.313 sec)\n",
      "INFO:tensorflow:global_step/sec: 310.19\n",
      "INFO:tensorflow:loss = 75029860000.0, step = 46801 (0.325 sec)\n",
      "INFO:tensorflow:global_step/sec: 305.086\n",
      "INFO:tensorflow:loss = 55387513000.0, step = 46901 (0.330 sec)\n",
      "INFO:tensorflow:global_step/sec: 288.925\n",
      "INFO:tensorflow:loss = 53629768000.0, step = 47001 (0.342 sec)\n",
      "INFO:tensorflow:global_step/sec: 297.867\n",
      "INFO:tensorflow:loss = 40491380000.0, step = 47101 (0.335 sec)\n",
      "INFO:tensorflow:global_step/sec: 294.673\n",
      "INFO:tensorflow:loss = 101087120000.0, step = 47201 (0.339 sec)\n",
      "INFO:tensorflow:global_step/sec: 312.56\n",
      "INFO:tensorflow:loss = 65666966000.0, step = 47301 (0.322 sec)\n",
      "INFO:tensorflow:global_step/sec: 320.218\n",
      "INFO:tensorflow:loss = 107294966000.0, step = 47401 (0.312 sec)\n",
      "INFO:tensorflow:global_step/sec: 297.779\n",
      "INFO:tensorflow:loss = 111607650000.0, step = 47501 (0.333 sec)\n",
      "INFO:tensorflow:global_step/sec: 300.67\n",
      "INFO:tensorflow:loss = 70189420000.0, step = 47601 (0.333 sec)\n",
      "INFO:tensorflow:global_step/sec: 299.47\n",
      "INFO:tensorflow:loss = 63191850000.0, step = 47701 (0.334 sec)\n",
      "INFO:tensorflow:global_step/sec: 296.917\n",
      "INFO:tensorflow:loss = 39665484000.0, step = 47801 (0.336 sec)\n",
      "INFO:tensorflow:global_step/sec: 306.233\n",
      "INFO:tensorflow:loss = 129857750000.0, step = 47901 (0.329 sec)\n",
      "INFO:tensorflow:global_step/sec: 296.378\n",
      "INFO:tensorflow:loss = 172688400000.0, step = 48001 (0.335 sec)\n",
      "INFO:tensorflow:global_step/sec: 292.628\n",
      "INFO:tensorflow:loss = 33037898000.0, step = 48101 (0.342 sec)\n",
      "INFO:tensorflow:global_step/sec: 286.581\n",
      "INFO:tensorflow:loss = 62253097000.0, step = 48201 (0.348 sec)\n",
      "INFO:tensorflow:global_step/sec: 315.87\n",
      "INFO:tensorflow:loss = 51584033000.0, step = 48301 (0.317 sec)\n",
      "INFO:tensorflow:global_step/sec: 320.784\n",
      "INFO:tensorflow:loss = 26357578000.0, step = 48401 (0.314 sec)\n",
      "INFO:tensorflow:global_step/sec: 318.262\n",
      "INFO:tensorflow:loss = 95801434000.0, step = 48501 (0.312 sec)\n",
      "INFO:tensorflow:global_step/sec: 306.888\n",
      "INFO:tensorflow:loss = 61480060000.0, step = 48601 (0.326 sec)\n",
      "INFO:tensorflow:global_step/sec: 285.335\n",
      "INFO:tensorflow:loss = 118677160000.0, step = 48701 (0.350 sec)\n",
      "INFO:tensorflow:global_step/sec: 299.677\n",
      "INFO:tensorflow:loss = 45887693000.0, step = 48801 (0.334 sec)\n",
      "INFO:tensorflow:global_step/sec: 293.275\n",
      "INFO:tensorflow:loss = 39892312000.0, step = 48901 (0.341 sec)\n",
      "INFO:tensorflow:global_step/sec: 270.115\n",
      "INFO:tensorflow:loss = 36320494000.0, step = 49001 (0.370 sec)\n",
      "INFO:tensorflow:global_step/sec: 294.886\n",
      "INFO:tensorflow:loss = 51623436000.0, step = 49101 (0.340 sec)\n",
      "INFO:tensorflow:global_step/sec: 306.461\n",
      "INFO:tensorflow:loss = 49732764000.0, step = 49201 (0.326 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 315.549\n",
      "INFO:tensorflow:loss = 110604040000.0, step = 49301 (0.324 sec)\n",
      "INFO:tensorflow:global_step/sec: 295.121\n",
      "INFO:tensorflow:loss = 61481247000.0, step = 49401 (0.332 sec)\n",
      "INFO:tensorflow:global_step/sec: 300.133\n",
      "INFO:tensorflow:loss = 175061140000.0, step = 49501 (0.334 sec)\n",
      "INFO:tensorflow:global_step/sec: 299.031\n",
      "INFO:tensorflow:loss = 106473470000.0, step = 49601 (0.334 sec)\n",
      "INFO:tensorflow:global_step/sec: 318.153\n",
      "INFO:tensorflow:loss = 27745290000.0, step = 49701 (0.314 sec)\n",
      "INFO:tensorflow:global_step/sec: 300.628\n",
      "INFO:tensorflow:loss = 134166080000.0, step = 49801 (0.332 sec)\n",
      "INFO:tensorflow:global_step/sec: 248.766\n",
      "INFO:tensorflow:loss = 38531070000.0, step = 49901 (0.402 sec)\n",
      "INFO:tensorflow:global_step/sec: 226.604\n",
      "INFO:tensorflow:loss = 71215050000.0, step = 50001 (0.454 sec)\n",
      "INFO:tensorflow:global_step/sec: 171.673\n",
      "INFO:tensorflow:loss = 52005786000.0, step = 50101 (0.578 sec)\n",
      "INFO:tensorflow:global_step/sec: 163.284\n",
      "INFO:tensorflow:loss = 52297180000.0, step = 50201 (0.612 sec)\n",
      "INFO:tensorflow:global_step/sec: 258.847\n",
      "INFO:tensorflow:loss = 19264797000.0, step = 50301 (0.386 sec)\n",
      "INFO:tensorflow:global_step/sec: 264.21\n",
      "INFO:tensorflow:loss = 38640180000.0, step = 50401 (0.372 sec)\n",
      "INFO:tensorflow:global_step/sec: 274.689\n",
      "INFO:tensorflow:loss = 106558620000.0, step = 50501 (0.363 sec)\n",
      "INFO:tensorflow:global_step/sec: 284.225\n",
      "INFO:tensorflow:loss = 49062375000.0, step = 50601 (0.352 sec)\n",
      "INFO:tensorflow:global_step/sec: 245.805\n",
      "INFO:tensorflow:loss = 101273530000.0, step = 50701 (0.407 sec)\n",
      "INFO:tensorflow:global_step/sec: 294.242\n",
      "INFO:tensorflow:loss = 59960558000.0, step = 50801 (0.340 sec)\n",
      "INFO:tensorflow:global_step/sec: 293.61\n",
      "INFO:tensorflow:loss = 45724050000.0, step = 50901 (0.341 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 51000 into /var/folders/0t/3d36yk2909g3l_5vhfrmv5gr0000gn/T/tmpxik1dusy/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 60667412000.0.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow_estimator.python.estimator.canned.dnn.DNNRegressor at 0x7fa3b7df6400>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train(input_fn=input_func,steps=25000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Create a prediction input function and then use the .predict method off your estimator model to create a list or predictions on your test data. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_input_func = tf.estimator.inputs.pandas_input_fn(\n",
    "      x=X_test,\n",
    "      batch_size=10,\n",
    "      num_epochs=1,\n",
    "      shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_gen = model.predict(predict_input_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/0t/3d36yk2909g3l_5vhfrmv5gr0000gn/T/tmpxik1dusy/model.ckpt-51000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    }
   ],
   "source": [
    "predictions = list(pred_gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Calculate the RMSE. You should be able to get around 100,000 RMSE (remember that this is in the same units as the label.) Do this manually or use [sklearn.metrics](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_error.html) **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_pred = [pred['predictions'] for pred in predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ideal = 97921.93181985477"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "91519.68721471839"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test,final_pred)**0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Great Job!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfdeeplearning",
   "language": "python",
   "name": "tfdeeplearning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
